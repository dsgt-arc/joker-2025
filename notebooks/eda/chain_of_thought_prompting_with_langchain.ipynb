{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dWlLXdG-Heq",
        "outputId": "e410df7e-82df-49c5-ef33-6091d737f2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.31)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.3.1)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.3.2 tiktoken-0.8.0\n",
            "Collecting langchain_anthropic\n",
            "  Downloading langchain_anthropic-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting anthropic<1,>=0.41.0 (from langchain_anthropic)\n",
            "  Downloading anthropic-0.45.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from langchain_anthropic) (0.7.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain_anthropic) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain_anthropic) (2.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.41.0->langchain_anthropic) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (0.3.1)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.27.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.41.0->langchain_anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.41.0->langchain_anthropic) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.41.0->langchain_anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.41.0->langchain_anthropic) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_anthropic) (2.3.0)\n",
            "Downloading langchain_anthropic-0.3.4-py3-none-any.whl (22 kB)\n",
            "Downloading anthropic-0.45.2-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain_anthropic\n",
            "Successfully installed anthropic-0.45.2 langchain_anthropic-0.3.4\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain_openai\n",
        "%pip install langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "\n",
        "config['api-keys'] = {\n",
        "    'gpt-4o': '[OPENAI-API-KEY]', # https://platform.openai.com/api-keys\n",
        "    'claude-3-5-sonnet-20240620': '[ANTHROPIC-API-KEY]', # https://console.anthropic.com/settings/keys\n",
        "    'deepseek-chat': '[DEEPSEEK-API-KEY]', # https://platform.deepseek.com/api_keys\n",
        "    'deepseek-reasoner': '[DEEPSEEK-API-KEY]' # https://platform.deepseek.com/api_keys\n",
        "}\n",
        "\n",
        "# Write the config file\n",
        "with open('config.ini', 'w') as configfile:\n",
        "    config.write(configfile)"
      ],
      "metadata": {
        "id": "-lPZChKy-JFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read('config.ini')\n",
        "\n",
        "max_tokens = 1024\n",
        "instructions = \"\"\"\n",
        "Step 1: Identify the two parts of the pun, not the two meanings of the homonym. Each part may be a word or a phrase. Respond in this format: parts = (part 1, part 2)\n",
        "\n",
        "Step 2: Identify the two meanings of the homonym. The homonym may be a word or a phrase. Then give a short definition of each meaning. Use this format: english homonym = (english word or phrase 1, definition 1, english word or phrase 2, defintion 2)\n",
        "\n",
        "Step 3: Does there exist a homonym in French the same or similar meanings? If so, respond using this format: french homonym = (french word or phrase 1, definition 1, french word or phrase 2, definition 2)\n",
        "\n",
        "Step 4: Generate a French pun.\n",
        "\n",
        "step 5: Translate the generated French pun into English.\n",
        "\n",
        "step 6: Explain why the French pun is funny.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "pun = \"Input: What do you call a vegan burger? A misteak.\"\n",
        "\n",
        "input = instructions + pun\n",
        "\n",
        "model = 'gpt-4o'\n",
        "api_key = config.get('api-keys', 'gpt-4o')\n",
        "llm = ChatOpenAI(model=model, api_key=api_key, max_tokens=max_tokens)\n",
        "response = llm.invoke(input)\n",
        "print(model, '\\n', response.content, '\\n')\n",
        "\n",
        "model = 'claude-3-5-sonnet-20240620'\n",
        "api_key = config.get('api-keys', 'claude-3-5-sonnet-20240620')\n",
        "llm = ChatAnthropic(model=model, api_key=api_key, max_tokens=max_tokens)\n",
        "response = llm.invoke(input)\n",
        "print(model, '\\n', response.content, '\\n')\n",
        "\n",
        "model = 'deepseek-chat'\n",
        "api_key = config.get('api-keys', 'deepseek-chat')\n",
        "llm = ChatOpenAI(model=model, api_key=api_key, openai_api_base='https://api.deepseek.com', max_tokens=max_tokens)\n",
        "response = llm.invoke(input)\n",
        "print(model, '\\n', response.content, '\\n')\n",
        "\n",
        "model = 'deepseek-reasoner'\n",
        "api_key = config.get('api-keys', 'deepseek-reasoner')\n",
        "llm = ChatOpenAI(model=model, api_key=api_key, openai_api_base='https://api.deepseek.com', max_tokens=max_tokens)\n",
        "response = llm.invoke(input)\n",
        "print(model, '\\n', response.content, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moQeUt4U-LIP",
        "outputId": "386e3e8d-3d3b-4f60-f65f-31e8b102f9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4o \n",
            " Step 1: Identify the two parts of the pun, not the two meanings of the homonym. Each part may be a word or a phrase. \n",
            "\n",
            "parts = (mistake, steak)\n",
            "\n",
            "Step 2: Identify the two meanings of the homonym. The homonym may be a word or a phrase. Then give a short definition of each meaning.\n",
            "\n",
            "english homonym = (mistake, an error or fault, misteak, a playful alteration of \"steak\" to imply a vegan burger)\n",
            "\n",
            "Step 3: Does there exist a homonym in French with the same or similar meanings?\n",
            "\n",
            "french homonym = (erreur, a mistake or error, un jeu de mots autour du mot \"steak\" pour un burger végétalien)\n",
            "\n",
            "Step 4: Generate a French pun.\n",
            "\n",
            "Que dit un végétalien quand il commande un burger? \"C'est une erreuf !\"\n",
            "\n",
            "Step 5: Translate the generated French pun into English.\n",
            "\n",
            "What does a vegan say when ordering a burger? \"It's a missteak!\"\n",
            "\n",
            "Step 6: Explain why the French pun is funny.\n",
            "\n",
            "The French pun is funny because it plays on the word \"erreur\" (mistake) by altering it to \"erreuf,\" which sounds like an incorrect or acknowledged mistake, similar to the English pun using \"misteak\" to humorously suggest the absence of actual steak in a vegan burger. Both versions of the pun play on the misappropriation of terms to imply a humorous mishap or unexpected situation. \n",
            "\n",
            "claude-3-5-sonnet-20240620 \n",
            " Step 1: parts = (misteak, mistake)\n",
            "\n",
            "Step 2: english homonym = (steak, a cut of meat, mistake, an error or blunder)\n",
            "\n",
            "Step 3: french homonym = (steak, morceau de viande, erreur, faute ou bévue)\n",
            "Note: In French, \"steak\" is used as a loanword from English, and \"erreur\" is not a homonym with it.\n",
            "\n",
            "Step 4: Qu'est-ce qu'un végétarien appelle un steak ? Une grosse boulette !\n",
            "\n",
            "Step 5: What does a vegetarian call a steak? A big meatball!\n",
            "\n",
            "Step 6: This French pun is funny because \"boulette\" has two meanings in French:\n",
            "1. A small ball of ground meat, similar to a meatball.\n",
            "2. A mistake or blunder (in colloquial French).\n",
            "\n",
            "The pun plays on these two meanings, suggesting that for a vegetarian, eating a steak would be a big mistake (une grosse boulette), while also referencing a meat product (boulette as meatball). This creates a humorous contradiction, as vegetarians don't eat meat, making the idea of a steak a \"mistake\" for them both literally and figuratively. \n",
            "\n",
            "deepseek-chat \n",
            " **Step 1:**  \n",
            "parts = (vegan burger, misteak)  \n",
            "\n",
            "**Step 2:**  \n",
            "english homonym = (mistake, an error or something done incorrectly, misteak, a play on words combining \"miss\" and \"steak\" to humorously refer to a vegan burger)  \n",
            "\n",
            "**Step 3:**  \n",
            "french homonym = (steak, a slice of meat, especially beef, stèque, a playful non-existent word combining \"steak\" and \"végétal\" to refer to a vegan burger)  \n",
            "\n",
            "**Step 4:**  \n",
            "French pun: Comment appelle-t-on un burger végétalien ? Un stèque.  \n",
            "\n",
            "**Step 5:**  \n",
            "English translation: What do you call a vegan burger? A stèque.  \n",
            "\n",
            "**Step 6:**  \n",
            "The French pun is funny because it plays on the similarity between \"steak\" (a meat product) and the invented word \"stèque,\" which humorously suggests a vegan alternative. The humor lies in the unexpected twist and the clever wordplay, which mirrors the original English pun. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0vHmYaN-wSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}